现在我们要做v2版本的需求：
1，在v2版本，我们需要添加一个“一个键优化提示词”的功能
2，这个功能的入口是前端web页面上工作空间里，在下载视频按钮下方添加一个新的“一键优化提示词按钮”
3，当用户点击“一键优化提示词“按钮后”，通过传递到后端的工作空间id，后端能拿到当前工作空间的所有数据，
   包括图片，
   视频生成基本参数：视频时长，宽高比，视频质量，
   运动控制：运动强度，主体运动描述，
   运镜方式，
   景别，
   光线，
   已生成的视频，
   基于这些数据信息，设计一个多agent提示词优化系统。
4，这个多agent提示词优化系统包含一个总导演master agent和 sub agent意图分析，sub agent视频分析，
   这三个agent。一个主agent两个子agent。
   agent提示词优化系统的核心流程：

    一.	意图分析sub agent执行

	◦	基于用户输入的数据，也就是工作空间里除已生成视频外的所有数据，分析用户的意图也就是用户真正想生成什么样的视频，
        输出结构化的意图拆解报告，输出物需提交至 Human in the Loop 环节，等待用户确认/修正。

	二.	Human in the Loop 介入触发

	◦	主控制节点（总导演 master agent）发起流程暂停，调用人工介入环节。

	◦	核心动作：用户意图校验，需用户确认意图分析结果的准确性。

	三.	视频分析sub agent执行

	◦	仅在用户确认意图分析结果后启动，对现有已生成视频成片进行多维度分析。

	◦	分析维度包括：内容匹配度（与意图的契合程度）、镜头语言合理性、节奏流畅度、技术指标达标情况（如画质、收音）。

	四.	总导演（master）决策输出

	◦	整合意图分析sub agent结论与视频分析sub agent结论，定位 NG 核心原因（如内容偏离意图、镜头运用不当、节奏拖沓等）。

	◦	生成具体解决方案：包含重拍/修改的具体步骤、镜头调整建议、用户提示词重写方向。

	◦	最终将 NG 原因+整改方案同步至用户，形成闭环。

关键节点逻辑

	•	强依赖关系：视频分析必须滞后于意图分析的用户确认，避免无效分析。

	•	核心决策源：总导演（master agent）是串联三大模块（Human in the Loop、意图分析sub agent、视频分析sub agent）的中枢。

	•	用户交互点：仅存在两处——意图确认环节、最终 NG 原因+整改方案接收环节。

5,一键优化提示词功能的产品交互

   一，在工作空间右半部分ai协作助手的上面添加一个”ai输出区“。
   用户点击”一键优化提示词“按钮后，浏览器web页面会自动把焦点和视觉移动到工作空间的顶部右侧ai输出区，因为”一键优化提示词“按钮是在工作空间
   底部的。在ai输出区会使用websocket技术流式输出ai在后台的工作进度，也就是agent提示词优化系统的核心流程，给用户看到一种ai一直在工作且
   工作内容与步骤透明的过程。ai输出区会持续输出ai在后台的工作内容，当输出内容把ai协作助手推到工作空间底部时，ai输出区需要有一个垂直的滚动条，
   确保ai协作助手不会被推出工作空间，一切都在工作空间的容器内。
   
   二，在ai输出区有Human in the Loop的确认。

   三，在ai输出区有最终ng原因和整改方案，对改动的数据：
        视频生成基本参数：视频时长，宽高比，视频质量，
        运动控制：运动强度，主体运动描述，
        运镜方式，
        景别，
        光线，
        需要对比给出原数据和改动后的数据，并自动改变工作空间表单里的数据，这样用户只需要直接点击生成视频，就可以生成一键优化过提示词后的视频了。